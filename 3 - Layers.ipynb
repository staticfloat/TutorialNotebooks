{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h"
     ]
    },
    {
     "data": {
      "text/html": [
       "    <script class='js-collapse-script'>\n",
       "        var curMatch =\n",
       "            window.location.href\n",
       "            .match(/(.*?)\\/notebooks\\/.*\\.ipynb/);\n",
       "\n",
       "        curMatch = curMatch ||\n",
       "            window.location.href\n",
       "            .match(/(.*?)\\/apps\\/.*\\.ipynb/);\n",
       "\n",
       "        if ( curMatch ) {\n",
       "            $('head').append('<base href=\"' + curMatch[1] + '/\">');\n",
       "        }\n",
       "    </script>\n"
      ],
      "text/plain": [
       "HTML{String}(\"    <script class='js-collapse-script'>\\n        var curMatch =\\n            window.location.href\\n            .match(/(.*?)\\\\/notebooks\\\\/.*\\\\.ipynb/);\\n\\n        curMatch = curMatch ||\\n            window.location.href\\n            .match(/(.*?)\\\\/apps\\\\/.*\\\\.ipynb/);\\n\\n        if ( curMatch ) {\\n            \\$('head').append('<base href=\\\"' + curMatch[1] + '/\\\">');\\n        }\\n    </script>\\n\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script class='js-collapse-script' src='/assetserver/51a259f5332d28582ebdae3acf84872b5676ad5d-assets/webio/dist/bundle.js'></script>"
      ],
      "text/plain": [
       "HTML{String}(\"<script class='js-collapse-script' src='/assetserver/51a259f5332d28582ebdae3acf84872b5676ad5d-assets/webio/dist/bundle.js'></script>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script class='js-collapse-script' src='/assetserver/51a259f5332d28582ebdae3acf84872b5676ad5d-assets/providers/ijulia_setup.js'></script>"
      ],
      "text/plain": [
       "HTML{String}(\"<script class='js-collapse-script' src='/assetserver/51a259f5332d28582ebdae3acf84872b5676ad5d-assets/providers/ijulia_setup.js'></script>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "  <script class='js-collapse-script'>\n",
       "    $('.js-collapse-script').parent('.output_subarea').css('padding', '0');\n",
       "  </script>\n"
      ],
      "text/plain": [
       "HTML{String}(\"  <script class='js-collapse-script'>\\n    \\$('.js-collapse-script').parent('.output_subarea').css('padding', '0');\\n  </script>\\n\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use package versions builtin to this repository.\n",
    "import Pkg, Random\n",
    "Pkg.activate(@__DIR__)\n",
    "Pkg.instantiate()\n",
    "\n",
    "# Load Flux and PlotlyJS for sweet interactive graphics\n",
    "using Flux, PlotlyJS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flux by Example: Layers\n",
    "\n",
    "Continuing from the previous example, we have run into some problems with using polynomials as the fundamental unit of computation for building our nonlinear function approximator.  Although our results improve as we increase the order of the polynomial, we rapidly run out of precision due to numbers being raised to very large powers; coefficients then needing to become extremely small, etc...\n",
    "\n",
    "This brings us to the beginnings of modern deep learning, with the humble fully connected layer and activation function.  We will use an affine transformation and simple nonlinearity as a building block, and then _compose_ those simple building blocks so as to create a model where each piece is itself very simple, but the overall model expressiveness is sufficient for the most complex of functions.  Stating this mathematically, our basic building block (what we will refer to as a \"fully connected layer\" with a \"relu activation\") is:\n",
    "\n",
    "$$\n",
    "    f(x) = \\text{relu}(Wx + b)\n",
    "$$\n",
    "\n",
    "Where $\\text{relu}(x)$ is a simple nonlinearity, applied element-by-element to its input:\n",
    "\n",
    "$$\n",
    "    \\text{relu}(x) = \\begin{cases}\n",
    "        x & \\quad x > 0 \\\\\n",
    "        0 & \\quad x \\le 0\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "Defining this building block in Flux is, as always, very simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct FullyConnected\n",
    "    W\n",
    "    b\n",
    "end\n",
    "\n",
    "Flux.@treelike FullyConnected\n",
    "\n",
    "function (fc::FullyConnected)(x)\n",
    "    return relu.(fc.W*x .+ fc.b)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will then be defined as a _composition_ of these building blocks, each with their own $W$ and $b$ parameters.  For example, with a stack of three of these building blocks, our model would be:\n",
    "\n",
    "$$\n",
    "    model(x) = f_3(f_2(f_1(x)))\n",
    "$$\n",
    "\n",
    "Flux gives us a convenient abstraction for stacking multiple building blocks (often called \"layers\") on top of eachother; the `Chain()` method.  We will create a model here with three layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tracked 1Ã—1 Array{Float64,2}:\n",
       " 0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Chain(\n",
    "    FullyConnected(param(randn(1,1)), param(randn(1))),\n",
    "    FullyConnected(param(randn(1,1)), param(randn(1))),\n",
    "    FullyConnected(param(randn(1,1)), param(randn(1))),\n",
    ")\n",
    "\n",
    "model(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we define our training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define training loop function; takes in a model to train, an\n",
    "# optimizer and a list of tuples mapping input (`x`) to output (`y`).\n",
    "function train(model, opt, training_data::Vector{T}) where {T <: Tuple}\n",
    "    for (x, y) in training_data\n",
    "        # Push `x` through the model\n",
    "        y_hat = model(x)\n",
    "        \n",
    "        # Calculate the loss and backpropagate it\n",
    "        loss = sum((y_hat .- y).^2)/length(y)\n",
    "        Flux.back!(loss)\n",
    "        \n",
    "        # Update the weights by taking an optimizer step\n",
    "        opt()\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
